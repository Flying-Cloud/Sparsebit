{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantization Aware Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "from enum import Enum\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch.multiprocessing as mp\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from model import resnet20\n",
    "from sparsebit.quantization import QuantModel, parse_qconfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Preparation\n",
    "## 1.0 Check your device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not torch.cuda.is_available():\n",
    "    raise NotImplementedError(\"This example should run on a GPU device.\")    #确定在GPU上运行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = \"qconfig.yaml\"    #QAT配置文件——包括量化方式（dorefa/lsq），权重和激活值的量化bit数等\n",
    "workers =4\n",
    "epochs = 200\n",
    "start_epoch = 0\n",
    "batch_size = 128\n",
    "lr =0.1\n",
    "momentum = 0.9\n",
    "weight_decay =1e-4\n",
    "print_freq = 10\n",
    "pretrained=\"\"\n",
    "qconfig = parse_qconfig(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Import the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet20(num_classes=10)    #以resnet20作为基础模型\n",
    "if pretrained:    #可以采用pretrained中保存的模型参数\n",
    "    ckpt_state_dict = torch.load(pretrained)\n",
    "    model.load_state_dict(ckpt_state_dict)\n",
    "\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Load CIFAR10 trainset and testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomHorizontalFlip(),    #随机水平翻转\n",
    "        transforms.RandomCrop(32, 4),    #随机裁剪\n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),    #指定各通道均值和标准差，将数据归一化\n",
    "    ]\n",
    ")\n",
    "\n",
    "trainset = datasets.CIFAR10(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=workers,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "testset = datasets.CIFAR10(\n",
    "    root=\"./data\", train=False, download=True, transform=transform\n",
    ")\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=workers,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Turn the model into QuantModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opcode         name                   target                   args                                   kwargs\n",
      "-------------  ---------------------  -----------------------  -------------------------------------  --------\n",
      "placeholder    x                      x                        ()                                     {}\n",
      "call_module    conv1                  conv1                    (x,)                                   {}\n",
      "call_module    bn1                    bn1                      (conv1,)                               {}\n",
      "call_module    relu                   relu                     (bn1,)                                 {}\n",
      "call_module    layer1_0_conv1         layer1.0.conv1           (relu,)                                {}\n",
      "call_module    layer1_0_bn1           layer1.0.bn1             (layer1_0_conv1,)                      {}\n",
      "call_module    layer1_0_relu          layer1.0.relu            (layer1_0_bn1,)                        {}\n",
      "call_module    layer1_0_conv2         layer1.0.conv2           (layer1_0_relu,)                       {}\n",
      "call_module    layer1_0_bn2           layer1.0.bn2             (layer1_0_conv2,)                      {}\n",
      "call_function  add                    <built-in function add>  (layer1_0_bn2, relu)                   {}\n",
      "call_module    layer1_0_relu_1        layer1.0.relu            (add,)                                 {}\n",
      "call_module    layer1_1_conv1         layer1.1.conv1           (layer1_0_relu_1,)                     {}\n",
      "call_module    layer1_1_bn1           layer1.1.bn1             (layer1_1_conv1,)                      {}\n",
      "call_module    layer1_1_relu          layer1.1.relu            (layer1_1_bn1,)                        {}\n",
      "call_module    layer1_1_conv2         layer1.1.conv2           (layer1_1_relu,)                       {}\n",
      "call_module    layer1_1_bn2           layer1.1.bn2             (layer1_1_conv2,)                      {}\n",
      "call_function  add_1                  <built-in function add>  (layer1_1_bn2, layer1_0_relu_1)        {}\n",
      "call_module    layer1_1_relu_1        layer1.1.relu            (add_1,)                               {}\n",
      "call_module    layer1_2_conv1         layer1.2.conv1           (layer1_1_relu_1,)                     {}\n",
      "call_module    layer1_2_bn1           layer1.2.bn1             (layer1_2_conv1,)                      {}\n",
      "call_module    layer1_2_relu          layer1.2.relu            (layer1_2_bn1,)                        {}\n",
      "call_module    layer1_2_conv2         layer1.2.conv2           (layer1_2_relu,)                       {}\n",
      "call_module    layer1_2_bn2           layer1.2.bn2             (layer1_2_conv2,)                      {}\n",
      "call_function  add_2                  <built-in function add>  (layer1_2_bn2, layer1_1_relu_1)        {}\n",
      "call_module    layer1_2_relu_1        layer1.2.relu            (add_2,)                               {}\n",
      "call_module    layer2_0_conv1         layer2.0.conv1           (layer1_2_relu_1,)                     {}\n",
      "call_module    layer2_0_bn1           layer2.0.bn1             (layer2_0_conv1,)                      {}\n",
      "call_module    layer2_0_relu          layer2.0.relu            (layer2_0_bn1,)                        {}\n",
      "call_module    layer2_0_conv2         layer2.0.conv2           (layer2_0_relu,)                       {}\n",
      "call_module    layer2_0_bn2           layer2.0.bn2             (layer2_0_conv2,)                      {}\n",
      "call_module    layer2_0_downsample_0  layer2.0.downsample.0    (layer1_2_relu_1,)                     {}\n",
      "call_module    layer2_0_downsample_1  layer2.0.downsample.1    (layer2_0_downsample_0,)               {}\n",
      "call_function  add_3                  <built-in function add>  (layer2_0_bn2, layer2_0_downsample_1)  {}\n",
      "call_module    layer2_0_relu_1        layer2.0.relu            (add_3,)                               {}\n",
      "call_module    layer2_1_conv1         layer2.1.conv1           (layer2_0_relu_1,)                     {}\n",
      "call_module    layer2_1_bn1           layer2.1.bn1             (layer2_1_conv1,)                      {}\n",
      "call_module    layer2_1_relu          layer2.1.relu            (layer2_1_bn1,)                        {}\n",
      "call_module    layer2_1_conv2         layer2.1.conv2           (layer2_1_relu,)                       {}\n",
      "call_module    layer2_1_bn2           layer2.1.bn2             (layer2_1_conv2,)                      {}\n",
      "call_function  add_4                  <built-in function add>  (layer2_1_bn2, layer2_0_relu_1)        {}\n",
      "call_module    layer2_1_relu_1        layer2.1.relu            (add_4,)                               {}\n",
      "call_module    layer2_2_conv1         layer2.2.conv1           (layer2_1_relu_1,)                     {}\n",
      "call_module    layer2_2_bn1           layer2.2.bn1             (layer2_2_conv1,)                      {}\n",
      "call_module    layer2_2_relu          layer2.2.relu            (layer2_2_bn1,)                        {}\n",
      "call_module    layer2_2_conv2         layer2.2.conv2           (layer2_2_relu,)                       {}\n",
      "call_module    layer2_2_bn2           layer2.2.bn2             (layer2_2_conv2,)                      {}\n",
      "call_function  add_5                  <built-in function add>  (layer2_2_bn2, layer2_1_relu_1)        {}\n",
      "call_module    layer2_2_relu_1        layer2.2.relu            (add_5,)                               {}\n",
      "call_module    layer3_0_conv1         layer3.0.conv1           (layer2_2_relu_1,)                     {}\n",
      "call_module    layer3_0_bn1           layer3.0.bn1             (layer3_0_conv1,)                      {}\n",
      "call_module    layer3_0_relu          layer3.0.relu            (layer3_0_bn1,)                        {}\n",
      "call_module    layer3_0_conv2         layer3.0.conv2           (layer3_0_relu,)                       {}\n",
      "call_module    layer3_0_bn2           layer3.0.bn2             (layer3_0_conv2,)                      {}\n",
      "call_module    layer3_0_downsample_0  layer3.0.downsample.0    (layer2_2_relu_1,)                     {}\n",
      "call_module    layer3_0_downsample_1  layer3.0.downsample.1    (layer3_0_downsample_0,)               {}\n",
      "call_function  add_6                  <built-in function add>  (layer3_0_bn2, layer3_0_downsample_1)  {}\n",
      "call_module    layer3_0_relu_1        layer3.0.relu            (add_6,)                               {}\n",
      "call_module    layer3_1_conv1         layer3.1.conv1           (layer3_0_relu_1,)                     {}\n",
      "call_module    layer3_1_bn1           layer3.1.bn1             (layer3_1_conv1,)                      {}\n",
      "call_module    layer3_1_relu          layer3.1.relu            (layer3_1_bn1,)                        {}\n",
      "call_module    layer3_1_conv2         layer3.1.conv2           (layer3_1_relu,)                       {}\n",
      "call_module    layer3_1_bn2           layer3.1.bn2             (layer3_1_conv2,)                      {}\n",
      "call_function  add_7                  <built-in function add>  (layer3_1_bn2, layer3_0_relu_1)        {}\n",
      "call_module    layer3_1_relu_1        layer3.1.relu            (add_7,)                               {}\n",
      "call_module    layer3_2_conv1         layer3.2.conv1           (layer3_1_relu_1,)                     {}\n",
      "call_module    layer3_2_bn1           layer3.2.bn1             (layer3_2_conv1,)                      {}\n",
      "call_module    layer3_2_relu          layer3.2.relu            (layer3_2_bn1,)                        {}\n",
      "call_module    layer3_2_conv2         layer3.2.conv2           (layer3_2_relu,)                       {}\n",
      "call_module    layer3_2_bn2           layer3.2.bn2             (layer3_2_conv2,)                      {}\n",
      "call_function  add_8                  <built-in function add>  (layer3_2_bn2, layer3_1_relu_1)        {}\n",
      "call_module    layer3_2_relu_1        layer3.2.relu            (add_8,)                               {}\n",
      "call_module    avgpool                avgpool                  (layer3_2_relu_1,)                     {}\n",
      "call_module    flatten                flatten                  (avgpool,)                             {}\n",
      "call_module    fc                     fc                       (flatten,)                             {}\n",
      "output         output                 output                   (fc,)                                  {}\n",
      "opcode       name                   target                 args                                     kwargs\n",
      "-----------  ---------------------  ---------------------  ---------------------------------------  --------\n",
      "placeholder  x                      x                      ()                                       {}\n",
      "call_module  conv1_1                conv1                  (x,)                                     {}\n",
      "call_module  bn1_1                  bn1                    (conv1_1,)                               {}\n",
      "call_module  relu_1                 relu                   (bn1_1,)                                 {}\n",
      "call_module  layer1_0_conv1_1       layer1_0_conv1         (relu_1,)                                {}\n",
      "call_module  layer1_0_bn1_1         layer1_0_bn1           (layer1_0_conv1_1,)                      {}\n",
      "call_module  layer1_0_relu_2        layer1_0_relu          (layer1_0_bn1_1,)                        {}\n",
      "call_module  layer1_0_conv2_1       layer1_0_conv2         (layer1_0_relu_2,)                       {}\n",
      "call_module  layer1_0_bn2_1         layer1_0_bn2           (layer1_0_conv2_1,)                      {}\n",
      "call_module  add_9                  add                    (layer1_0_bn2_1, relu_1)                 {}\n",
      "call_module  layer1_0_relu_3        layer1_0_relu_1        (add_9,)                                 {}\n",
      "call_module  layer1_1_conv1_1       layer1_1_conv1         (layer1_0_relu_3,)                       {}\n",
      "call_module  layer1_1_bn1_1         layer1_1_bn1           (layer1_1_conv1_1,)                      {}\n",
      "call_module  layer1_1_relu_2        layer1_1_relu          (layer1_1_bn1_1,)                        {}\n",
      "call_module  layer1_1_conv2_1       layer1_1_conv2         (layer1_1_relu_2,)                       {}\n",
      "call_module  layer1_1_bn2_1         layer1_1_bn2           (layer1_1_conv2_1,)                      {}\n",
      "call_module  add_10                 add_1                  (layer1_1_bn2_1, layer1_0_relu_3)        {}\n",
      "call_module  layer1_1_relu_3        layer1_1_relu_1        (add_10,)                                {}\n",
      "call_module  layer1_2_conv1_1       layer1_2_conv1         (layer1_1_relu_3,)                       {}\n",
      "call_module  layer1_2_bn1_1         layer1_2_bn1           (layer1_2_conv1_1,)                      {}\n",
      "call_module  layer1_2_relu_2        layer1_2_relu          (layer1_2_bn1_1,)                        {}\n",
      "call_module  layer1_2_conv2_1       layer1_2_conv2         (layer1_2_relu_2,)                       {}\n",
      "call_module  layer1_2_bn2_1         layer1_2_bn2           (layer1_2_conv2_1,)                      {}\n",
      "call_module  add_11                 add_2                  (layer1_2_bn2_1, layer1_1_relu_3)        {}\n",
      "call_module  layer1_2_relu_3        layer1_2_relu_1        (add_11,)                                {}\n",
      "call_module  layer2_0_conv1_1       layer2_0_conv1         (layer1_2_relu_3,)                       {}\n",
      "call_module  layer2_0_bn1_1         layer2_0_bn1           (layer2_0_conv1_1,)                      {}\n",
      "call_module  layer2_0_relu_2        layer2_0_relu          (layer2_0_bn1_1,)                        {}\n",
      "call_module  layer2_0_conv2_1       layer2_0_conv2         (layer2_0_relu_2,)                       {}\n",
      "call_module  layer2_0_bn2_1         layer2_0_bn2           (layer2_0_conv2_1,)                      {}\n",
      "call_module  layer2_0_downsample_2  layer2_0_downsample_0  (layer1_2_relu_3,)                       {}\n",
      "call_module  layer2_0_downsample_3  layer2_0_downsample_1  (layer2_0_downsample_2,)                 {}\n",
      "call_module  add_12                 add_3                  (layer2_0_bn2_1, layer2_0_downsample_3)  {}\n",
      "call_module  layer2_0_relu_3        layer2_0_relu_1        (add_12,)                                {}\n",
      "call_module  layer2_1_conv1_1       layer2_1_conv1         (layer2_0_relu_3,)                       {}\n",
      "call_module  layer2_1_bn1_1         layer2_1_bn1           (layer2_1_conv1_1,)                      {}\n",
      "call_module  layer2_1_relu_2        layer2_1_relu          (layer2_1_bn1_1,)                        {}\n",
      "call_module  layer2_1_conv2_1       layer2_1_conv2         (layer2_1_relu_2,)                       {}\n",
      "call_module  layer2_1_bn2_1         layer2_1_bn2           (layer2_1_conv2_1,)                      {}\n",
      "call_module  add_13                 add_4                  (layer2_1_bn2_1, layer2_0_relu_3)        {}\n",
      "call_module  layer2_1_relu_3        layer2_1_relu_1        (add_13,)                                {}\n",
      "call_module  layer2_2_conv1_1       layer2_2_conv1         (layer2_1_relu_3,)                       {}\n",
      "call_module  layer2_2_bn1_1         layer2_2_bn1           (layer2_2_conv1_1,)                      {}\n",
      "call_module  layer2_2_relu_2        layer2_2_relu          (layer2_2_bn1_1,)                        {}\n",
      "call_module  layer2_2_conv2_1       layer2_2_conv2         (layer2_2_relu_2,)                       {}\n",
      "call_module  layer2_2_bn2_1         layer2_2_bn2           (layer2_2_conv2_1,)                      {}\n",
      "call_module  add_14                 add_5                  (layer2_2_bn2_1, layer2_1_relu_3)        {}\n",
      "call_module  layer2_2_relu_3        layer2_2_relu_1        (add_14,)                                {}\n",
      "call_module  layer3_0_conv1_1       layer3_0_conv1         (layer2_2_relu_3,)                       {}\n",
      "call_module  layer3_0_bn1_1         layer3_0_bn1           (layer3_0_conv1_1,)                      {}\n",
      "call_module  layer3_0_relu_2        layer3_0_relu          (layer3_0_bn1_1,)                        {}\n",
      "call_module  layer3_0_conv2_1       layer3_0_conv2         (layer3_0_relu_2,)                       {}\n",
      "call_module  layer3_0_bn2_1         layer3_0_bn2           (layer3_0_conv2_1,)                      {}\n",
      "call_module  layer3_0_downsample_2  layer3_0_downsample_0  (layer2_2_relu_3,)                       {}\n",
      "call_module  layer3_0_downsample_3  layer3_0_downsample_1  (layer3_0_downsample_2,)                 {}\n",
      "call_module  add_15                 add_6                  (layer3_0_bn2_1, layer3_0_downsample_3)  {}\n",
      "call_module  layer3_0_relu_3        layer3_0_relu_1        (add_15,)                                {}\n",
      "call_module  layer3_1_conv1_1       layer3_1_conv1         (layer3_0_relu_3,)                       {}\n",
      "call_module  layer3_1_bn1_1         layer3_1_bn1           (layer3_1_conv1_1,)                      {}\n",
      "call_module  layer3_1_relu_2        layer3_1_relu          (layer3_1_bn1_1,)                        {}\n",
      "call_module  layer3_1_conv2_1       layer3_1_conv2         (layer3_1_relu_2,)                       {}\n",
      "call_module  layer3_1_bn2_1         layer3_1_bn2           (layer3_1_conv2_1,)                      {}\n",
      "call_module  add_16                 add_7                  (layer3_1_bn2_1, layer3_0_relu_3)        {}\n",
      "call_module  layer3_1_relu_3        layer3_1_relu_1        (add_16,)                                {}\n",
      "call_module  layer3_2_conv1_1       layer3_2_conv1         (layer3_1_relu_3,)                       {}\n",
      "call_module  layer3_2_bn1_1         layer3_2_bn1           (layer3_2_conv1_1,)                      {}\n",
      "call_module  layer3_2_relu_2        layer3_2_relu          (layer3_2_bn1_1,)                        {}\n",
      "call_module  layer3_2_conv2_1       layer3_2_conv2         (layer3_2_relu_2,)                       {}\n",
      "call_module  layer3_2_bn2_1         layer3_2_bn2           (layer3_2_conv2_1,)                      {}\n",
      "call_module  add_17                 add_8                  (layer3_2_bn2_1, layer3_1_relu_3)        {}\n",
      "call_module  layer3_2_relu_3        layer3_2_relu_1        (add_17,)                                {}\n",
      "call_module  avgpool_1              avgpool                (layer3_2_relu_3,)                       {}\n",
      "call_module  flatten_1              flatten                (avgpool_1,)                             {}\n",
      "call_module  fc_1                   fc                     (flatten_1,)                             {}\n",
      "output       output                 output                 (fc_1,)                                  {}\n"
     ]
    }
   ],
   "source": [
    "model = QuantModel(model, qconfig).cuda()    #将model转化为量化模型，以支持后续QAT的各种量化操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Define loss function, optimizer and learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr,\n",
    "    momentum=momentum,\n",
    "    weight_decay=weight_decay,\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "    optimizer, milestones=[100, 150], last_epoch=start_epoch - 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. QAT\n",
    "## 2.1 Calibration\n",
    "通过calibration统计参数范围，初步确定量化scale和zeropoint（后续QAT训练时还会调整），目前使用256张输入图像来统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphModule(\n",
      "  (conv1): QConv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)fake_fused: False\n",
      "  \tweight_quantizer: LSQ, int4\t qmin: -8  qmax: 7, qscheme: torch.per_channel_symmetric, observer=minmax, scale=[0.0476, 0.0933], zp=[0.0, 0.0]\n",
      "  (bn1): QBatchNorm2d fake_fused: True\n",
      "  (relu): QReLU(inplace=True)fake_fused: True\n",
      "  (layer1_0_conv1): QConv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)fake_fused: False\n",
      "  \tweight_quantizer: LSQ, int4\t qmin: -8  qmax: 7, qscheme: torch.per_channel_symmetric, observer=minmax, scale=[0.0592, 0.0776], zp=[0.0, 0.0]\n",
      "  \tinput_quantizer: LSQ, uint4\t qmin: 0  qmax: 15, qscheme: torch.per_tensor_affine, observer=minmax, scale=0.1386, zp=0.0000\n",
      "  (layer1_0_bn1): QBatchNorm2d fake_fused: True\n",
      "  (layer1_0_relu): QReLU(inplace=True)fake_fused: True\n",
      "  (layer1_0_conv2): QConv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)fake_fused: False\n",
      "  \tweight_quantizer: LSQ, int4\t qmin: -8  qmax: 7, qscheme: torch.per_channel_symmetric, observer=minmax, scale=[0.0631, 0.0814], zp=[0.0, 0.0]\n",
      "  \tinput_quantizer: LSQ, uint4\t qmin: 0  qmax: 15, qscheme: torch.per_tensor_affine, observer=minmax, scale=0.1176, zp=0.0000\n",
      "  (layer1_0_bn2): QBatchNorm2d fake_fused: True\n",
      "  (add): QAddfake_fused: True\n",
      "  (layer1_0_relu_1): QReLU(inplace=True)fake_fused: True\n",
      "  (layer1_1_conv1): QConv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)fake_fused: False\n",
      "  \tweight_quantizer: LSQ, int4\t qmin: -8  qmax: 7, qscheme: torch.per_channel_symmetric, observer=minmax, scale=[0.0654, 0.0766], zp=[0.0, 0.0]\n",
      "  \tinput_quantizer: LSQ, uint4\t qmin: 0  qmax: 15, qscheme: torch.per_tensor_affine, observer=minmax, scale=0.2276, zp=0.0000\n",
      "  (layer1_1_bn1): QBatchNorm2d fake_fused: True\n",
      "  (layer1_1_relu): QReLU(inplace=True)fake_fused: True\n",
      "  (layer1_1_conv2): QConv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)fake_fused: False\n",
      "  \tweight_quantizer: LSQ, int4\t qmin: -8  qmax: 7, qscheme: torch.per_channel_symmetric, observer=minmax, scale=[0.0629, 0.0809], zp=[0.0, 0.0]\n",
      "  \tinput_quantizer: LSQ, uint4\t qmin: 0  qmax: 15, qscheme: torch.per_tensor_affine, observer=minmax, scale=0.0859, zp=0.0000\n",
      "  (layer1_1_bn2): QBatchNorm2d fake_fused: True\n",
      "  (add_1): QAddfake_fused: True\n",
      "  (layer1_1_relu_1): QReLU(inplace=True)fake_fused: True\n",
      "  (layer1_2_conv1): QConv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)fake_fused: False\n",
      "  \tweight_quantizer: LSQ, int4\t qmin: -8  qmax: 7, qscheme: torch.per_channel_symmetric, observer=minmax, scale=[0.0620, 0.0818], zp=[0.0, 0.0]\n",
      "  \tinput_quantizer: LSQ, uint4\t qmin: 0  qmax: 15, qscheme: torch.per_tensor_affine, observer=minmax, scale=0.2985, zp=0.0000\n",
      "  (layer1_2_bn1): QBatchNorm2d fake_fused: True\n",
      "  (layer1_2_relu): QReLU(inplace=True)fake_fused: True\n",
      "  (layer1_2_conv2): QConv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)fake_fused: False\n",
      "  \tweight_quantizer: LSQ, int4\t qmin: -8  qmax: 7, qscheme: torch.per_channel_symmetric, observer=minmax, scale=[0.0680, 0.0804], zp=[0.0, 0.0]\n",
      "  \tinput_quantizer: LSQ, uint4\t qmin: 0  qmax: 15, qscheme: torch.per_tensor_affine, observer=minmax, scale=0.2151, zp=0.0000\n",
      "  (layer1_2_bn2): QBatchNorm2d fake_fused: True\n",
      "  (add_2): QAddfake_fused: True\n",
      "  (layer1_2_relu_1): QReLU(inplace=True)fake_fused: True\n",
      "  (layer2_0_conv1): QConv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)fake_fused: False\n",
      "  \tweight_quantizer: LSQ, int4\t qmin: -8  qmax: 7, qscheme: torch.per_channel_symmetric, observer=minmax, scale=[0.0439, 0.0553], zp=[0.0, 0.0]\n",
      "  \tinput_quantizer: LSQ, uint4\t qmin: 0  qmax: 15, qscheme: torch.per_tensor_affine, observer=minmax, scale=0.3644, zp=0.0000\n",
      "  (layer2_0_bn1): QBatchNorm2d fake_fused: True\n",
      "  (layer2_0_relu): QReLU(inplace=True)fake_fused: True\n",
      "  (layer2_0_conv2): QConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)fake_fused: False\n",
      "  \tweight_quantizer: LSQ, int4\t qmin: -8  qmax: 7, qscheme: torch.per_channel_symmetric, observer=minmax, scale=[0.0456, 0.0556], zp=[0.0, 0.0]\n",
      "  \tinput_quantizer: LSQ, uint4\t qmin: 0  qmax: 15, qscheme: torch.per_tensor_affine, observer=minmax, scale=0.2172, zp=0.0000\n",
      "  (layer2_0_bn2): QBatchNorm2d fake_fused: True\n",
      "  (layer2_0_downsample_0): QConv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)fake_fused: False\n",
      "  \tweight_quantizer: LSQ, int4\t qmin: -8  qmax: 7, qscheme: torch.per_channel_symmetric, observer=minmax, scale=[0.0882, 0.1875], zp=[0.0, 0.0]\n",
      "  \tinput_quantizer: LSQ, uint4\t qmin: 0  qmax: 15, qscheme: torch.per_tensor_affine, observer=minmax, scale=0.3644, zp=0.0000\n",
      "  (layer2_0_downsample_1): QBatchNorm2d fake_fused: True\n",
      "  (add_3): QAddfake_fused: True\n",
      "  (layer2_0_relu_1): QReLU(inplace=True)fake_fused: True\n",
      "  (layer2_1_conv1): QConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)fake_fused: False\n",
      "  \tweight_quantizer: LSQ, int4\t qmin: -8  qmax: 7, qscheme: torch.per_channel_symmetric, observer=minmax, scale=[0.0454, 0.0544], zp=[0.0, 0.0]\n",
      "  \tinput_quantizer: LSQ, uint4\t qmin: 0  qmax: 15, qscheme: torch.per_tensor_affine, observer=minmax, scale=0.2786, zp=0.0000\n",
      "  (layer2_1_bn1): QBatchNorm2d fake_fused: True\n",
      "  (layer2_1_relu): QReLU(inplace=True)fake_fused: True\n",
      "  (layer2_1_conv2): QConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)fake_fused: False\n",
      "  \tweight_quantizer: LSQ, int4\t qmin: -8  qmax: 7, qscheme: torch.per_channel_symmetric, observer=minmax, scale=[0.0440, 0.0551], zp=[0.0, 0.0]\n",
      "  \tinput_quantizer: LSQ, uint4\t qmin: 0  qmax: 15, qscheme: torch.per_tensor_affine, observer=minmax, scale=0.2935, zp=0.0000\n",
      "  (layer2_1_bn2): QBatchNorm2d fake_fused: True\n",
      "  (add_4): QAddfake_fused: True\n",
      "  (layer2_1_relu_1): QReLU(inplace=True)fake_fused: True\n",
      "  (layer2_2_conv1): QConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)fake_fused: False\n",
      "  \tweight_quantizer: LSQ, int4\t qmin: -8  qmax: 7, qscheme: torch.per_channel_symmetric, observer=minmax, scale=[0.0456, 0.0552], zp=[0.0, 0.0]\n",
      "  \tinput_quantizer: LSQ, uint4\t qmin: 0  qmax: 15, qscheme: torch.per_tensor_affine, observer=minmax, scale=0.5013, zp=0.0000\n",
      "  (layer2_2_bn1): QBatchNorm2d fake_fused: True\n",
      "  (layer2_2_relu): QReLU(inplace=True)fake_fused: True\n",
      "  (layer2_2_conv2): QConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)fake_fused: False\n",
      "  \tweight_quantizer: LSQ, int4\t qmin: -8  qmax: 7, qscheme: torch.per_channel_symmetric, observer=minmax, scale=[0.0471, 0.0550], zp=[0.0, 0.0]\n",
      "  \tinput_quantizer: LSQ, uint4\t qmin: 0  qmax: 15, qscheme: torch.per_tensor_affine, observer=minmax, scale=0.2870, zp=0.0000\n",
      "  (layer2_2_bn2): QBatchNorm2d fake_fused: True\n",
      "  (add_5): QAddfake_fused: True\n",
      "  (layer2_2_relu_1): QReLU(inplace=True)fake_fused: True\n",
      "  (layer3_0_conv1): QConv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)fake_fused: False\n",
      "  \tweight_quantizer: LSQ, int4\t qmin: -8  qmax: 7, qscheme: torch.per_channel_symmetric, observer=minmax, scale=[0.0327, 0.0386], zp=[0.0, 0.0]\n",
      "  \tinput_quantizer: LSQ, uint4\t qmin: 0  qmax: 15, qscheme: torch.per_tensor_affine, observer=minmax, scale=0.6891, zp=0.0000\n",
      "  (layer3_0_bn1): QBatchNorm2d fake_fused: True\n",
      "  (layer3_0_relu): QReLU(inplace=True)fake_fused: True\n",
      "  (layer3_0_conv2): QConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)fake_fused: False\n",
      "  \tweight_quantizer: LSQ, int4\t qmin: -8  qmax: 7, qscheme: torch.per_channel_symmetric, observer=minmax, scale=[0.0332, 0.0381], zp=[0.0, 0.0]\n",
      "  \tinput_quantizer: LSQ, uint4\t qmin: 0  qmax: 15, qscheme: torch.per_tensor_affine, observer=minmax, scale=0.3876, zp=0.0000\n",
      "  (layer3_0_bn2): QBatchNorm2d fake_fused: True\n",
      "  (layer3_0_downsample_0): QConv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)fake_fused: False\n",
      "  \tweight_quantizer: LSQ, int4\t qmin: -8  qmax: 7, qscheme: torch.per_channel_symmetric, observer=minmax, scale=[0.0706, 0.1469], zp=[0.0, 0.0]\n",
      "  \tinput_quantizer: LSQ, uint4\t qmin: 0  qmax: 15, qscheme: torch.per_tensor_affine, observer=minmax, scale=0.6891, zp=0.0000\n",
      "  (layer3_0_downsample_1): QBatchNorm2d fake_fused: True\n",
      "  (add_6): QAddfake_fused: True\n",
      "  (layer3_0_relu_1): QReLU(inplace=True)fake_fused: True\n",
      "  (layer3_1_conv1): QConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)fake_fused: False\n",
      "  \tweight_quantizer: LSQ, int4\t qmin: -8  qmax: 7, qscheme: torch.per_channel_symmetric, observer=minmax, scale=[0.0330, 0.0399], zp=[0.0, 0.0]\n",
      "  \tinput_quantizer: LSQ, uint4\t qmin: 0  qmax: 15, qscheme: torch.per_tensor_affine, observer=minmax, scale=0.4794, zp=0.0000\n",
      "  (layer3_1_bn1): QBatchNorm2d fake_fused: True\n",
      "  (layer3_1_relu): QReLU(inplace=True)fake_fused: True\n",
      "  (layer3_1_conv2): QConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)fake_fused: False\n",
      "  \tweight_quantizer: LSQ, int4\t qmin: -8  qmax: 7, qscheme: torch.per_channel_symmetric, observer=minmax, scale=[0.0325, 0.0380], zp=[0.0, 0.0]\n",
      "  \tinput_quantizer: LSQ, uint4\t qmin: 0  qmax: 15, qscheme: torch.per_tensor_affine, observer=minmax, scale=0.4670, zp=0.0000\n",
      "  (layer3_1_bn2): QBatchNorm2d fake_fused: True\n",
      "  (add_7): QAddfake_fused: True\n",
      "  (layer3_1_relu_1): QReLU(inplace=True)fake_fused: True\n",
      "  (layer3_2_conv1): QConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)fake_fused: False\n",
      "  \tweight_quantizer: LSQ, int4\t qmin: -8  qmax: 7, qscheme: torch.per_channel_symmetric, observer=minmax, scale=[0.0332, 0.0378], zp=[0.0, 0.0]\n",
      "  \tinput_quantizer: LSQ, uint4\t qmin: 0  qmax: 15, qscheme: torch.per_tensor_affine, observer=minmax, scale=0.8395, zp=0.0000\n",
      "  (layer3_2_bn1): QBatchNorm2d fake_fused: True\n",
      "  (layer3_2_relu): QReLU(inplace=True)fake_fused: True\n",
      "  (layer3_2_conv2): QConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)fake_fused: False\n",
      "  \tweight_quantizer: LSQ, int4\t qmin: -8  qmax: 7, qscheme: torch.per_channel_symmetric, observer=minmax, scale=[0.0331, 0.0377], zp=[0.0, 0.0]\n",
      "  \tinput_quantizer: LSQ, uint4\t qmin: 0  qmax: 15, qscheme: torch.per_tensor_affine, observer=minmax, scale=0.6792, zp=0.0000\n",
      "  (layer3_2_bn2): QBatchNorm2d fake_fused: True\n",
      "  (add_8): QAddfake_fused: True\n",
      "  (layer3_2_relu_1): QReLU(inplace=True)fake_fused: True\n",
      "  (avgpool): QAdaptiveAvgPool2d(output_size=(1, 1))fake_fused: False\n",
      "  \tinput_quantizer: LSQ, uint4\t qmin: 0  qmax: 15, qscheme: torch.per_tensor_affine, observer=minmax, scale=1.0699, zp=0.0000\n",
      "  (flatten): Flatten()\n",
      "  (fc): QLinear(in_features=64, out_features=10, bias=True)fake_fused: False\n",
      "  \tweight_quantizer: LSQ, int8\t qmin: -128  qmax: 127, qscheme: torch.per_channel_symmetric, observer=minmax, scale=[0.0412, 0.0544], zp=[0.0, 0.0]\n",
      "  \tinput_quantizer: LSQ, uint4\t qmin: 0  qmax: 15, qscheme: torch.per_tensor_affine, observer=minmax, scale=1.0699, zp=0.0000\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "def forward(self, x):\n",
      "    conv1_1 = self.conv1(x);  x = None\n",
      "    bn1_1 = self.bn1(conv1_1);  conv1_1 = None\n",
      "    relu_1 = self.relu(bn1_1);  bn1_1 = None\n",
      "    layer1_0_conv1_1 = self.layer1_0_conv1(relu_1)\n",
      "    layer1_0_bn1_1 = self.layer1_0_bn1(layer1_0_conv1_1);  layer1_0_conv1_1 = None\n",
      "    layer1_0_relu_2 = self.layer1_0_relu(layer1_0_bn1_1);  layer1_0_bn1_1 = None\n",
      "    layer1_0_conv2_1 = self.layer1_0_conv2(layer1_0_relu_2);  layer1_0_relu_2 = None\n",
      "    layer1_0_bn2_1 = self.layer1_0_bn2(layer1_0_conv2_1);  layer1_0_conv2_1 = None\n",
      "    add_9 = self.add(layer1_0_bn2_1, relu_1);  layer1_0_bn2_1 = relu_1 = None\n",
      "    layer1_0_relu_3 = self.layer1_0_relu_1(add_9);  add_9 = None\n",
      "    layer1_1_conv1_1 = self.layer1_1_conv1(layer1_0_relu_3)\n",
      "    layer1_1_bn1_1 = self.layer1_1_bn1(layer1_1_conv1_1);  layer1_1_conv1_1 = None\n",
      "    layer1_1_relu_2 = self.layer1_1_relu(layer1_1_bn1_1);  layer1_1_bn1_1 = None\n",
      "    layer1_1_conv2_1 = self.layer1_1_conv2(layer1_1_relu_2);  layer1_1_relu_2 = None\n",
      "    layer1_1_bn2_1 = self.layer1_1_bn2(layer1_1_conv2_1);  layer1_1_conv2_1 = None\n",
      "    add_10 = self.add_1(layer1_1_bn2_1, layer1_0_relu_3);  layer1_1_bn2_1 = layer1_0_relu_3 = None\n",
      "    layer1_1_relu_3 = self.layer1_1_relu_1(add_10);  add_10 = None\n",
      "    layer1_2_conv1_1 = self.layer1_2_conv1(layer1_1_relu_3)\n",
      "    layer1_2_bn1_1 = self.layer1_2_bn1(layer1_2_conv1_1);  layer1_2_conv1_1 = None\n",
      "    layer1_2_relu_2 = self.layer1_2_relu(layer1_2_bn1_1);  layer1_2_bn1_1 = None\n",
      "    layer1_2_conv2_1 = self.layer1_2_conv2(layer1_2_relu_2);  layer1_2_relu_2 = None\n",
      "    layer1_2_bn2_1 = self.layer1_2_bn2(layer1_2_conv2_1);  layer1_2_conv2_1 = None\n",
      "    add_11 = self.add_2(layer1_2_bn2_1, layer1_1_relu_3);  layer1_2_bn2_1 = layer1_1_relu_3 = None\n",
      "    layer1_2_relu_3 = self.layer1_2_relu_1(add_11);  add_11 = None\n",
      "    layer2_0_conv1_1 = self.layer2_0_conv1(layer1_2_relu_3)\n",
      "    layer2_0_bn1_1 = self.layer2_0_bn1(layer2_0_conv1_1);  layer2_0_conv1_1 = None\n",
      "    layer2_0_relu_2 = self.layer2_0_relu(layer2_0_bn1_1);  layer2_0_bn1_1 = None\n",
      "    layer2_0_conv2_1 = self.layer2_0_conv2(layer2_0_relu_2);  layer2_0_relu_2 = None\n",
      "    layer2_0_bn2_1 = self.layer2_0_bn2(layer2_0_conv2_1);  layer2_0_conv2_1 = None\n",
      "    layer2_0_downsample_2 = self.layer2_0_downsample_0(layer1_2_relu_3);  layer1_2_relu_3 = None\n",
      "    layer2_0_downsample_3 = self.layer2_0_downsample_1(layer2_0_downsample_2);  layer2_0_downsample_2 = None\n",
      "    add_12 = self.add_3(layer2_0_bn2_1, layer2_0_downsample_3);  layer2_0_bn2_1 = layer2_0_downsample_3 = None\n",
      "    layer2_0_relu_3 = self.layer2_0_relu_1(add_12);  add_12 = None\n",
      "    layer2_1_conv1_1 = self.layer2_1_conv1(layer2_0_relu_3)\n",
      "    layer2_1_bn1_1 = self.layer2_1_bn1(layer2_1_conv1_1);  layer2_1_conv1_1 = None\n",
      "    layer2_1_relu_2 = self.layer2_1_relu(layer2_1_bn1_1);  layer2_1_bn1_1 = None\n",
      "    layer2_1_conv2_1 = self.layer2_1_conv2(layer2_1_relu_2);  layer2_1_relu_2 = None\n",
      "    layer2_1_bn2_1 = self.layer2_1_bn2(layer2_1_conv2_1);  layer2_1_conv2_1 = None\n",
      "    add_13 = self.add_4(layer2_1_bn2_1, layer2_0_relu_3);  layer2_1_bn2_1 = layer2_0_relu_3 = None\n",
      "    layer2_1_relu_3 = self.layer2_1_relu_1(add_13);  add_13 = None\n",
      "    layer2_2_conv1_1 = self.layer2_2_conv1(layer2_1_relu_3)\n",
      "    layer2_2_bn1_1 = self.layer2_2_bn1(layer2_2_conv1_1);  layer2_2_conv1_1 = None\n",
      "    layer2_2_relu_2 = self.layer2_2_relu(layer2_2_bn1_1);  layer2_2_bn1_1 = None\n",
      "    layer2_2_conv2_1 = self.layer2_2_conv2(layer2_2_relu_2);  layer2_2_relu_2 = None\n",
      "    layer2_2_bn2_1 = self.layer2_2_bn2(layer2_2_conv2_1);  layer2_2_conv2_1 = None\n",
      "    add_14 = self.add_5(layer2_2_bn2_1, layer2_1_relu_3);  layer2_2_bn2_1 = layer2_1_relu_3 = None\n",
      "    layer2_2_relu_3 = self.layer2_2_relu_1(add_14);  add_14 = None\n",
      "    layer3_0_conv1_1 = self.layer3_0_conv1(layer2_2_relu_3)\n",
      "    layer3_0_bn1_1 = self.layer3_0_bn1(layer3_0_conv1_1);  layer3_0_conv1_1 = None\n",
      "    layer3_0_relu_2 = self.layer3_0_relu(layer3_0_bn1_1);  layer3_0_bn1_1 = None\n",
      "    layer3_0_conv2_1 = self.layer3_0_conv2(layer3_0_relu_2);  layer3_0_relu_2 = None\n",
      "    layer3_0_bn2_1 = self.layer3_0_bn2(layer3_0_conv2_1);  layer3_0_conv2_1 = None\n",
      "    layer3_0_downsample_2 = self.layer3_0_downsample_0(layer2_2_relu_3);  layer2_2_relu_3 = None\n",
      "    layer3_0_downsample_3 = self.layer3_0_downsample_1(layer3_0_downsample_2);  layer3_0_downsample_2 = None\n",
      "    add_15 = self.add_6(layer3_0_bn2_1, layer3_0_downsample_3);  layer3_0_bn2_1 = layer3_0_downsample_3 = None\n",
      "    layer3_0_relu_3 = self.layer3_0_relu_1(add_15);  add_15 = None\n",
      "    layer3_1_conv1_1 = self.layer3_1_conv1(layer3_0_relu_3)\n",
      "    layer3_1_bn1_1 = self.layer3_1_bn1(layer3_1_conv1_1);  layer3_1_conv1_1 = None\n",
      "    layer3_1_relu_2 = self.layer3_1_relu(layer3_1_bn1_1);  layer3_1_bn1_1 = None\n",
      "    layer3_1_conv2_1 = self.layer3_1_conv2(layer3_1_relu_2);  layer3_1_relu_2 = None\n",
      "    layer3_1_bn2_1 = self.layer3_1_bn2(layer3_1_conv2_1);  layer3_1_conv2_1 = None\n",
      "    add_16 = self.add_7(layer3_1_bn2_1, layer3_0_relu_3);  layer3_1_bn2_1 = layer3_0_relu_3 = None\n",
      "    layer3_1_relu_3 = self.layer3_1_relu_1(add_16);  add_16 = None\n",
      "    layer3_2_conv1_1 = self.layer3_2_conv1(layer3_1_relu_3)\n",
      "    layer3_2_bn1_1 = self.layer3_2_bn1(layer3_2_conv1_1);  layer3_2_conv1_1 = None\n",
      "    layer3_2_relu_2 = self.layer3_2_relu(layer3_2_bn1_1);  layer3_2_bn1_1 = None\n",
      "    layer3_2_conv2_1 = self.layer3_2_conv2(layer3_2_relu_2);  layer3_2_relu_2 = None\n",
      "    layer3_2_bn2_1 = self.layer3_2_bn2(layer3_2_conv2_1);  layer3_2_conv2_1 = None\n",
      "    add_17 = self.add_8(layer3_2_bn2_1, layer3_1_relu_3);  layer3_2_bn2_1 = layer3_1_relu_3 = None\n",
      "    layer3_2_relu_3 = self.layer3_2_relu_1(add_17);  add_17 = None\n",
      "    avgpool_1 = self.avgpool(layer3_2_relu_3);  layer3_2_relu_3 = None\n",
      "    flatten_1 = self.flatten(avgpool_1);  avgpool_1 = None\n",
      "    fc_1 = self.fc(flatten_1);  flatten_1 = None\n",
      "    return fc_1\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "model.prepare_calibration()    #进入calibration状态\n",
    "calib_size, cur_size = 256, 0\n",
    "#在eval模式且无需计算梯度的条件下用训练集进行calibrate\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data, target in trainloader:\n",
    "        model(data.cuda())\n",
    "        cur_size += data.shape[0]\n",
    "        if cur_size >= calib_size:\n",
    "            break\n",
    "model.init_QAT()    #调用API，初始化QAT\n",
    "model.set_lastmodule_wbit(bit=8)    #额外规定最后一层权重的量化bit数\n",
    "print(model.model)    #可以在print出的模型信息中看到网络各层weight和activation的量化scale和zeropoint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Train Function\n",
    "训练模型，与原模型的训练代码完全相同，fake quantize等过程在QuantModel中自行完成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter(\"Time\", \":6.3f\")\n",
    "    data_time = AverageMeter(\"Data\", \":6.3f\")\n",
    "    losses = AverageMeter(\"Loss\", \":.4e\")\n",
    "    top1 = AverageMeter(\"Acc@1\", \":6.2f\")\n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, losses, top1],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch),\n",
    "    )\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            images = images.cuda()\n",
    "            target = target.cuda()\n",
    "\n",
    "        # compute output\n",
    "        output = model(images)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc1 = accuracy(output, target, topk=(1,))[0]\n",
    "        losses.update(loss.item(), images.size(0))\n",
    "        top1.update(acc1[0], images.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            progress.display(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Validation Function\n",
    "验证部分代码也与原模型完全一致，量化在QuantModel中自行完成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion):\n",
    "    batch_time = AverageMeter(\"Time\", \":6.3f\", Summary.NONE)\n",
    "    losses = AverageMeter(\"Loss\", \":.4e\", Summary.NONE)\n",
    "    top1 = AverageMeter(\"Acc@1\", \":6.2f\", Summary.AVERAGE)\n",
    "    progress = ProgressMeter(\n",
    "        len(val_loader), [batch_time, losses, top1], prefix=\"Test: \"\n",
    "    )\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        start = time.time()\n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "            if torch.cuda.is_available():\n",
    "                images = images.cuda()\n",
    "                target = target.cuda()\n",
    "\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1 = accuracy(output, target, topk=(1,))[0]\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            top1.update(acc1[0], images.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % print_freq == 0:\n",
    "                progress.display(i)\n",
    "\n",
    "        progress.display_summary()\n",
    "\n",
    "    print(\"Total Time: {}\".format(time.time() - start))\n",
    "    return top1.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Tool Functions\n",
    "一些辅助性函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename=\"checkpoint.pth.tar\"):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, \"model_best.pth.tar\")\n",
    "\n",
    "class Summary(Enum):\n",
    "    NONE = 0\n",
    "    AVERAGE = 1\n",
    "    SUM = 2\n",
    "    COUNT = 3\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self, name, fmt=\":f\", summary_type=Summary.AVERAGE):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.summary_type = summary_type\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = \"{name} {val\" + self.fmt + \"} ({avg\" + self.fmt + \"})\"\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "    def summary(self):\n",
    "        fmtstr = \"\"\n",
    "        if self.summary_type is Summary.NONE:\n",
    "            fmtstr = \"\"\n",
    "        elif self.summary_type is Summary.AVERAGE:\n",
    "            fmtstr = \"{name} {avg:.3f}\"\n",
    "        elif self.summary_type is Summary.SUM:\n",
    "            fmtstr = \"{name} {sum:.3f}\"\n",
    "        elif self.summary_type is Summary.COUNT:\n",
    "            fmtstr = \"{name} {count:.3f}\"\n",
    "        else:\n",
    "            raise ValueError(\"invalid summary type %r\" % self.summary_type)\n",
    "\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print(\"\\t\".join(entries))\n",
    "\n",
    "    def display_summary(self):\n",
    "        entries = [\" *\"]\n",
    "        entries += [meter.summary() for meter in self.meters]\n",
    "        print(\" \".join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = \"{:\" + str(num_digits) + \"d}\"\n",
    "        return \"[\" + fmt + \"/\" + fmt.format(num_batches) + \"]\"\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Train and Validate\n",
    "QAT训练，并在每个epoch后进行验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][  0/391]\tTime  0.462 ( 0.462)\tData  0.363 ( 0.363)\tLoss 2.5532e+00 (2.5532e+00)\tAcc@1   7.81 (  7.81)\n",
      "Epoch: [0][ 10/391]\tTime  0.021 ( 0.069)\tData  0.000 ( 0.035)\tLoss 2.2397e+00 (2.3932e+00)\tAcc@1  16.41 ( 11.72)\n",
      "Epoch: [0][ 20/391]\tTime  0.026 ( 0.048)\tData  0.000 ( 0.018)\tLoss 1.9141e+00 (2.2925e+00)\tAcc@1  29.69 ( 15.62)\n",
      "Epoch: [0][ 30/391]\tTime  0.027 ( 0.041)\tData  0.000 ( 0.013)\tLoss 2.0419e+00 (2.2163e+00)\tAcc@1  25.00 ( 17.87)\n",
      "Epoch: [0][ 40/391]\tTime  0.019 ( 0.037)\tData  0.000 ( 0.010)\tLoss 2.1557e+00 (2.1969e+00)\tAcc@1  17.97 ( 18.37)\n",
      "Epoch: [0][ 50/391]\tTime  0.043 ( 0.035)\tData  0.000 ( 0.008)\tLoss 1.8642e+00 (2.1546e+00)\tAcc@1  28.12 ( 19.42)\n",
      "Epoch: [0][ 60/391]\tTime  0.031 ( 0.033)\tData  0.003 ( 0.007)\tLoss 2.0701e+00 (2.1247e+00)\tAcc@1  26.56 ( 20.57)\n",
      "Epoch: [0][ 70/391]\tTime  0.048 ( 0.033)\tData  0.025 ( 0.006)\tLoss 1.8509e+00 (2.0923e+00)\tAcc@1  33.59 ( 21.48)\n",
      "Epoch: [0][ 80/391]\tTime  0.025 ( 0.032)\tData  0.000 ( 0.005)\tLoss 1.8174e+00 (2.0619e+00)\tAcc@1  26.56 ( 22.58)\n",
      "Epoch: [0][ 90/391]\tTime  0.022 ( 0.032)\tData  0.000 ( 0.005)\tLoss 1.8695e+00 (2.0410e+00)\tAcc@1  30.47 ( 23.19)\n",
      "Epoch: [0][100/391]\tTime  0.037 ( 0.031)\tData  0.000 ( 0.004)\tLoss 1.8906e+00 (2.0239e+00)\tAcc@1  21.88 ( 23.46)\n",
      "Epoch: [0][110/391]\tTime  0.021 ( 0.031)\tData  0.000 ( 0.004)\tLoss 1.8694e+00 (2.0049e+00)\tAcc@1  29.69 ( 24.18)\n",
      "Epoch: [0][120/391]\tTime  0.022 ( 0.030)\tData  0.000 ( 0.004)\tLoss 1.6654e+00 (1.9856e+00)\tAcc@1  32.03 ( 24.81)\n",
      "Epoch: [0][130/391]\tTime  0.024 ( 0.030)\tData  0.000 ( 0.003)\tLoss 1.7176e+00 (1.9663e+00)\tAcc@1  32.81 ( 25.47)\n",
      "Epoch: [0][140/391]\tTime  0.041 ( 0.029)\tData  0.000 ( 0.003)\tLoss 1.7309e+00 (1.9470e+00)\tAcc@1  32.81 ( 26.07)\n",
      "Epoch: [0][150/391]\tTime  0.024 ( 0.029)\tData  0.000 ( 0.003)\tLoss 1.7604e+00 (1.9314e+00)\tAcc@1  30.47 ( 26.57)\n",
      "Epoch: [0][160/391]\tTime  0.030 ( 0.029)\tData  0.000 ( 0.003)\tLoss 1.5976e+00 (1.9188e+00)\tAcc@1  37.50 ( 27.08)\n",
      "Epoch: [0][170/391]\tTime  0.024 ( 0.029)\tData  0.000 ( 0.003)\tLoss 1.6667e+00 (1.9027e+00)\tAcc@1  35.16 ( 27.63)\n",
      "Epoch: [0][180/391]\tTime  0.023 ( 0.029)\tData  0.000 ( 0.003)\tLoss 1.6141e+00 (1.8906e+00)\tAcc@1  36.72 ( 28.15)\n",
      "Epoch: [0][190/391]\tTime  0.028 ( 0.029)\tData  0.000 ( 0.003)\tLoss 1.6812e+00 (1.8801e+00)\tAcc@1  41.41 ( 28.57)\n",
      "Epoch: [0][200/391]\tTime  0.025 ( 0.029)\tData  0.000 ( 0.003)\tLoss 1.5164e+00 (1.8673e+00)\tAcc@1  39.06 ( 29.16)\n",
      "Epoch: [0][210/391]\tTime  0.024 ( 0.029)\tData  0.000 ( 0.003)\tLoss 1.6000e+00 (1.8564e+00)\tAcc@1  42.97 ( 29.61)\n",
      "Epoch: [0][220/391]\tTime  0.038 ( 0.029)\tData  0.000 ( 0.002)\tLoss 1.6752e+00 (1.8486e+00)\tAcc@1  35.94 ( 29.89)\n",
      "Epoch: [0][230/391]\tTime  0.030 ( 0.029)\tData  0.000 ( 0.002)\tLoss 1.6474e+00 (1.8369e+00)\tAcc@1  35.94 ( 30.40)\n",
      "Epoch: [0][240/391]\tTime  0.032 ( 0.029)\tData  0.000 ( 0.002)\tLoss 1.7083e+00 (1.8254e+00)\tAcc@1  36.72 ( 30.92)\n",
      "Epoch: [0][250/391]\tTime  0.039 ( 0.029)\tData  0.000 ( 0.002)\tLoss 1.5762e+00 (1.8162e+00)\tAcc@1  46.88 ( 31.31)\n",
      "Epoch: [0][260/391]\tTime  0.033 ( 0.029)\tData  0.000 ( 0.002)\tLoss 1.5453e+00 (1.8073e+00)\tAcc@1  42.97 ( 31.73)\n",
      "Epoch: [0][270/391]\tTime  0.022 ( 0.029)\tData  0.000 ( 0.002)\tLoss 1.5344e+00 (1.7945e+00)\tAcc@1  46.09 ( 32.26)\n",
      "Epoch: [0][280/391]\tTime  0.026 ( 0.029)\tData  0.000 ( 0.002)\tLoss 1.5580e+00 (1.7840e+00)\tAcc@1  40.62 ( 32.70)\n",
      "Epoch: [0][290/391]\tTime  0.026 ( 0.029)\tData  0.000 ( 0.002)\tLoss 1.5485e+00 (1.7721e+00)\tAcc@1  49.22 ( 33.22)\n",
      "Epoch: [0][300/391]\tTime  0.029 ( 0.029)\tData  0.000 ( 0.002)\tLoss 1.4551e+00 (1.7621e+00)\tAcc@1  43.75 ( 33.68)\n",
      "Epoch: [0][310/391]\tTime  0.026 ( 0.029)\tData  0.000 ( 0.002)\tLoss 1.3466e+00 (1.7541e+00)\tAcc@1  55.47 ( 34.04)\n",
      "Epoch: [0][320/391]\tTime  0.022 ( 0.029)\tData  0.000 ( 0.002)\tLoss 1.5307e+00 (1.7440e+00)\tAcc@1  48.44 ( 34.48)\n",
      "Epoch: [0][330/391]\tTime  0.036 ( 0.028)\tData  0.000 ( 0.002)\tLoss 1.5009e+00 (1.7342e+00)\tAcc@1  46.09 ( 34.89)\n",
      "Epoch: [0][340/391]\tTime  0.036 ( 0.028)\tData  0.000 ( 0.002)\tLoss 1.3837e+00 (1.7254e+00)\tAcc@1  50.00 ( 35.25)\n",
      "Epoch: [0][350/391]\tTime  0.023 ( 0.028)\tData  0.000 ( 0.002)\tLoss 1.2799e+00 (1.7163e+00)\tAcc@1  53.91 ( 35.67)\n",
      "Epoch: [0][360/391]\tTime  0.022 ( 0.028)\tData  0.000 ( 0.002)\tLoss 1.5125e+00 (1.7068e+00)\tAcc@1  39.84 ( 36.03)\n",
      "Epoch: [0][370/391]\tTime  0.022 ( 0.028)\tData  0.000 ( 0.002)\tLoss 1.2614e+00 (1.6964e+00)\tAcc@1  56.25 ( 36.47)\n",
      "Epoch: [0][380/391]\tTime  0.022 ( 0.028)\tData  0.000 ( 0.002)\tLoss 1.3753e+00 (1.6884e+00)\tAcc@1  43.75 ( 36.79)\n",
      "Epoch: [0][390/391]\tTime  0.059 ( 0.028)\tData  0.000 ( 0.002)\tLoss 1.4980e+00 (1.6796e+00)\tAcc@1  43.75 ( 37.13)\n",
      "Test: [ 0/79]\tTime  0.392 ( 0.392)\tLoss 2.0751e+00 (2.0751e+00)\tAcc@1  35.16 ( 35.16)\n",
      "Test: [10/79]\tTime  0.006 ( 0.044)\tLoss 2.0890e+00 (2.0406e+00)\tAcc@1  28.91 ( 34.94)\n",
      "Test: [20/79]\tTime  0.006 ( 0.028)\tLoss 2.0763e+00 (2.0403e+00)\tAcc@1  33.59 ( 34.86)\n",
      "Test: [30/79]\tTime  0.006 ( 0.022)\tLoss 2.0897e+00 (2.0345e+00)\tAcc@1  29.69 ( 34.90)\n",
      "Test: [40/79]\tTime  0.014 ( 0.019)\tLoss 2.1623e+00 (2.0241e+00)\tAcc@1  32.03 ( 34.98)\n",
      "Test: [50/79]\tTime  0.006 ( 0.017)\tLoss 2.2602e+00 (2.0207e+00)\tAcc@1  29.69 ( 34.82)\n",
      "Test: [60/79]\tTime  0.004 ( 0.016)\tLoss 1.8909e+00 (2.0130e+00)\tAcc@1  41.41 ( 35.05)\n",
      "Test: [70/79]\tTime  0.004 ( 0.015)\tLoss 1.7809e+00 (2.0217e+00)\tAcc@1  39.06 ( 34.96)\n",
      " *   Acc@1 35.010\n",
      "Total Time: 1.3133676052093506\n",
      "Training is Done, best: 35.0099983215332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wanghedi/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:43: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  result = getattr(asarray(obj), method)(*args, **kwds)\n",
      "/data/jupyter/sparsebit/examples/cifar10_qat/sparsebit/quantization/quantizers/quant_tensor.py:156: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  scale = scale.item()\n",
      "/data/jupyter/sparsebit/examples/cifar10_qat/sparsebit/quantization/quantizers/quant_tensor.py:160: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  zero_point = zero_point.int().item()\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "ONNX defines [0, 255] for quint8 and [-128, 127] for qint8, got [-8, 7]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 31\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport_onnx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mqresnet20.onnx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m embed\n\u001b[1;32m     34\u001b[0m embed()\n",
      "File \u001b[0;32m/data/jupyter/sparsebit/examples/cifar10_qat/sparsebit/quantization/quant_model.py:223\u001b[0m, in \u001b[0;36mQuantModel.export_onnx\u001b[0;34m(self, dummy_data, name, input_names, output_names, dynamic_axes, opset_version, verbose, external_info)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(m, Quantizer):\n\u001b[1;32m    222\u001b[0m         m\u001b[38;5;241m.\u001b[39menable_export_onnx()\n\u001b[0;32m--> 223\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdummy_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopset_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mnamed_modules():\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(m, Quantizer):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/onnx/__init__.py:316\u001b[0m, in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, _retain_param_name, do_constant_folding, example_outputs, strip_doc_string, dynamic_axes, keep_initializers_as_inputs, custom_opsets, enable_onnx_checker, use_external_data_format)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03mExports a model into ONNX format. If ``model`` is not a\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03m:class:`torch.jit.ScriptModule` nor a :class:`torch.jit.ScriptFunction`, this runs\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;124;03m    model to the file ``f`` even if this is raised.\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[0;32m--> 316\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexport_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m                    \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m_retain_param_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_constant_folding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mstrip_doc_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcustom_opsets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menable_onnx_checker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_external_data_format\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/onnx/utils.py:107\u001b[0m, in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, _retain_param_name, do_constant_folding, example_outputs, strip_doc_string, dynamic_axes, keep_initializers_as_inputs, custom_opsets, enable_onnx_checker, use_external_data_format)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_external_data_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    103\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`use_external_data_format\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is deprecated and ignored. Will be removed in next \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    104\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPyTorch release. The code will work as it is False if models are not larger than 2GB, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    105\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOtherwise set to False because of size limits imposed by Protocol Buffers.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 107\u001b[0m \u001b[43m_export\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexport_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopset_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_constant_folding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_constant_folding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexample_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_opsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_opsets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_external_data_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_external_data_format\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/onnx/utils.py:724\u001b[0m, in \u001b[0;36m_export\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, example_outputs, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, use_external_data_format, onnx_shape_inference)\u001b[0m\n\u001b[1;32m    720\u001b[0m     dynamic_axes \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    721\u001b[0m _validate_dynamic_axes(dynamic_axes, model, input_names, output_names)\n\u001b[1;32m    723\u001b[0m graph, params_dict, torch_out \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m--> 724\u001b[0m     \u001b[43m_model_to_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m                    \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mexample_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_do_constant_folding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    727\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mfixed_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfixed_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    729\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;66;03m# TODO: Don't allocate a in-memory string for the protobuf\u001b[39;00m\n\u001b[1;32m    732\u001b[0m defer_weight_export \u001b[38;5;241m=\u001b[39m export_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ExportTypes\u001b[38;5;241m.\u001b[39mPROTOBUF_FILE\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/onnx/utils.py:497\u001b[0m, in \u001b[0;36m_model_to_graph\u001b[0;34m(model, args, verbose, input_names, output_names, operator_export_type, example_outputs, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size, training, dynamic_axes)\u001b[0m\n\u001b[1;32m    493\u001b[0m graph, params, torch_out, module \u001b[38;5;241m=\u001b[39m _create_jit_graph(model, args)\n\u001b[1;32m    495\u001b[0m params_dict \u001b[38;5;241m=\u001b[39m _get_named_param_dict(graph, params)\n\u001b[0;32m--> 497\u001b[0m graph \u001b[38;5;241m=\u001b[39m \u001b[43m_optimize_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m                        \u001b[49m\u001b[43m_disable_torch_constant_prop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_disable_torch_constant_prop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mfixed_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfixed_batch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mmodule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msymbolic_helper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _onnx_shape_inference\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mScriptModule) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mScriptFunction):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/onnx/utils.py:216\u001b[0m, in \u001b[0;36m_optimize_graph\u001b[0;34m(graph, operator_export_type, _disable_torch_constant_prop, fixed_batch_size, params_dict, dynamic_axes, input_names, module)\u001b[0m\n\u001b[1;32m    214\u001b[0m     dynamic_axes \u001b[38;5;241m=\u001b[39m {} \u001b[38;5;28;01mif\u001b[39;00m dynamic_axes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m dynamic_axes\n\u001b[1;32m    215\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_jit_pass_onnx_set_dynamic_input_shape(graph, dynamic_axes, input_names)\n\u001b[0;32m--> 216\u001b[0m graph \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jit_pass_onnx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_jit_pass_lint(graph)\n\u001b[1;32m    219\u001b[0m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_jit_pass_onnx_scalar_type_analysis(graph, \u001b[38;5;28;01mTrue\u001b[39;00m, _export_onnx_opset_version)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/onnx/__init__.py:373\u001b[0m, in \u001b[0;36m_run_symbolic_function\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_symbolic_function\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[0;32m--> 373\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_symbolic_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/onnx/utils.py:1032\u001b[0m, in \u001b[0;36m_run_symbolic_function\u001b[0;34m(g, block, n, inputs, env, operator_export_type)\u001b[0m\n\u001b[1;32m   1030\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1031\u001b[0m         attrs \u001b[38;5;241m=\u001b[39m {k: n[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m n\u001b[38;5;241m.\u001b[39mattributeNames()}\n\u001b[0;32m-> 1032\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msymbolic_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m ns \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprim\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1035\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m op_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConstant\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m n\u001b[38;5;241m.\u001b[39mmustBeNone():\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/onnx/symbolic_helper.py:172\u001b[0m, in \u001b[0;36mparse_args.<locals>.decorator.<locals>.wrapper\u001b[0;34m(g, *args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/onnx/symbolic_opset13.py:134\u001b[0m, in \u001b[0;36mfake_quantize_per_channel_affine\u001b[0;34m(g, inputs, scale, zero_point, axis, quant_min, quant_max)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;129m@parse_args\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfake_quantize_per_channel_affine\u001b[39m(g, inputs, scale, zero_point, axis, quant_min\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m128\u001b[39m, quant_max\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m127\u001b[39m):\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m quant_min \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m128\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m quant_max \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m127\u001b[39m, \u001b[38;5;241m255\u001b[39m]:\n\u001b[0;32m--> 134\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    135\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mONNX defines [0, 255] for quint8 and [-128, 127] for qint8, got [\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(quant_min, quant_max))\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;66;03m# ONNX defines zero_point to be int8 or uint8\u001b[39;00m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m quant_min \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: ONNX defines [0, 255] for quint8 and [-128, 127] for qint8, got [-8, 7]"
     ]
    }
   ],
   "source": [
    "best_acc1 = 0\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    # train for one epoch\n",
    "    train(trainloader, model, criterion, optimizer, epoch,)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    acc1 = validate(testloader, model, criterion)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # remember best acc@1 and save checkpoint\n",
    "    is_best = acc1 > best_acc1\n",
    "    best_acc1 = max(acc1, best_acc1)\n",
    "\n",
    "    save_checkpoint(\n",
    "       {\n",
    "           \"epoch\": epoch + 1,\n",
    "           \"state_dict\": model.state_dict(),\n",
    "           \"best_acc1\": best_acc1,\n",
    "           \"optimizer\": optimizer.state_dict(),\n",
    "           \"scheduler\": scheduler.state_dict(),\n",
    "       },\n",
    "       is_best,\n",
    "     )\n",
    "\n",
    "print(\"Training is Done, best: {}\".format(best_acc1))\n",
    "\n",
    "# export onnx\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    model.export_onnx(torch.randn(1, 3, 32,32), name=\"qresnet20.onnx\",extra_info=True)\n",
    "\n",
    "from IPython import embed\n",
    "embed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mykernel",
   "language": "python",
   "name": "mykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "bf3a63ab5f9f4019e467b64c02ed82b4d340692322a673bf824db751f55183b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
